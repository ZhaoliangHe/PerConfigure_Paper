\section{Introduction}
\label{Section: introduction}
With the increasing demand for continuous video analysis in public safety and transportation, more and more cameras are being deployed to various locations. Video analysis can be completed according to the video analysis application built by different models \textcolor{note}{misunderstand of different models, tangchen amend}, which can free the staff from complex and boring tasks or search through massive amounts of video data to find what you're looking for quickly. In recent years, we have also witnessed the emergence of a large number of excellent models for target detection.

For the collected video, the classical computer vision and deep neural network technology are generally used for video analysis. A video analysis application consists of a \emph{pipeline} of several video processing modules, typically including a decoder, a selective sampling frame application, and a target detector. Such a pipeline always has multiple \emph{knobs}, such as frame rate, resolution, and model (e.g., MobileNet, ResNet, or InceptionResNet). A combination of the knob values is a video analysis \emph{configuration}. The configuration space grows \emph{exponentially} with the number of knobs and their values. Since video analysis is a very complex process, we pay much attention to the consumption of resources in the calculation process, and the accuracy of inference is also our focus. Therefore, the problem that follows is how to balance \emph{resource consumption} and \emph{accuracy}. 

Choosing different configurations will affect the resource consumption and accuracy caused by video analysis. For example, using a complex model and high resolution can obviously accurately detect the target object, but it also requires more computing resources. However, choosing a simple model and low resolution can significantly reduce resource consumption, although it reduces the accuracy to some extent. And in the case of a highway video analysis, due to the rate of car travel cannot be predicted in advance, so when the car drives slowly (or static) because of the traffic jam, we can choose a lower frame rate (such as 1 FPS) without having to use a fixed on the whole video higher frame rate, this can significantly reduce resource consumption, but does not affect the accuracy of the video analysis. 

The \emph{best} configuration for a video analytics pipeline also varies over time, often at a timescale of minutes or even seconds \cite{jiang2018chameleon}. Hence, our goal is to find a range of ``most appropriate'' configurations that takes up the minimum amount of computing resources and is accurate to the desired threshold. On the one hand, if one only profiles the processing pipeline to choose the best configuration \emph{once}, the application would either waste resources (by picking an expensive configuration) or sacrifice accuracy (by picking a cheap configuration). On the other hand, if one periodically profiles the pipeline configurations to find an optimal resource-accuracy \emph{tradeoff} by exhaustive all configurations, it would be prohibitively expensive since the number of possible configurations is exponential in the number of knobs and their values, and thousands of configurations can be combined with just a few knobs.

%The most intuitive way to solve this problem is to find the best solution by exhaustive all configurations, but the number of possible configurations grows exponentially, and thousands of configurations can be combined with just a few knobs, so exhaustive configuration is a highly unrealistic approach.

For a video analytics application, choosing the ``most appropriate'' configuration is a complicated decision-making problem, which is challenging to be solved by rules. The reinforcement learning method is an excellent way to solve this unsupervised complex-environmental problem. In our solution, we tackle the following design challenges.

%Also, one is not provided the well-labeled data on which configuration should be used in which time of the video, meaning this is an unsupervised learning task.

\begin{itemize}	
\item \emph{The best configuration for a video analytics pipeline changes over time with the environment.} The real-word environment is non-stationary; for instance, tracking vehicles when traffic moves quickly requires a much higher frame rate than when traffic moves slowly, but when each condition occurs may vary by hour, minute, or second. As a dynamic video analysis configuration solution, we target to provide a solution that dynamically picks a configuration according to intrusive dynamics of video contents, i.e., it can \emph{generate} video analysis configuration for video analysis in a different time.

\item \emph{How to significantly reduce the resource cost of periodic configuration profiling.} The cost of periodically profiling often exceeds any resource savings gained by adapting the best configurations we end up selecting. We leverage a Reinforcement Learning-based agent to automatically pick the best configuration periodically, dramatically reducing the profiling cost. 

\item \emph{Lack of well-labeled training data.} In our problem, one is not provided the well-labeled data on which configuration should be used in which time of the video, as in conventional supervised deep learning tasks. In practice, such a video analysis configuration is usually utilized in an online manner, and the solution has to learn from the video contents automatically. 
\end{itemize}

To address the above challenges, we present a periodically configure approach based on reinforcement learning, called PerConfigure, which can dynamically select the ``most appropriate'' configuration according to intrusive dynamics of video contents, thus solving this difficult optimal configuration decision problem in a very low-cost way. The main contributions of this paper are summarized as follows.
\textcolor{note}{zhaoliang add more contributions}

\begin{itemize}
	
\item We design an interactive training environment that can be applied to different online computer vision-based services. We propose an asynchronous advantage actor-critic-based \cite{mnih2016asynchronous} agent to evaluate and predict the performance of a video analysis configuration on video analysis.

\item We build a reinforcement learning-based framework to train the agent in the above environment. The agent can learn to choose a ``most appropriate'' configuration for each timestamp of video analysis after iteratively interacting with the environment by feeding the carefully designed reward that considers both accuracy and resources.
 
\item PerConfigure can achieve xx-xx\% higher accuracy with the
same amount of resources, or achieve the same accuracy
with only xx-xx\% of the resources.
\end{itemize}

%The rest of this paper is organized as follows. We discuss related works in Section \ref{Section: related_works}. We present our framework and detailed design in Section \ref{Section: design}. We present our solution's performance in Section \ref{Section: evaluation} and conclude the paper in Section \ref{Section: conclusion}.