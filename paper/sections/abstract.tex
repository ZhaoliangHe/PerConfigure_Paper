\begin{abstract}
Deep convolutional neural networks (NN)-based video analytics services demand intensive computation resources and high inference accuracy. Due to the highly variable video context, the \emph{best} configuration (the most proper configuration) also varies over time. If one uses a static configuration solution (i.e., only profiles the video stream to choose the best configuration \emph{once}), the services would either waste resources (by picking an expensive configuration) or sacrifice accuracy (by selecting a cheap configuration). If one searches a large space of configurations periodically, it would cause an overwhelming resource overhead that far outstrips periodically profiling gains. Knowing this, designing an \emph{automatic} approach to decide the best configuration for the current video context is meaningful. This paper proposes a reinforcement learning (RL)-based automatic video analytics configuration framework, AutoConfigure. The unique feature of AutoConfigure is \emph{context-driven}, meaning that AutoConfigure can adapt the best configuration to intrusive dynamics of video contexts. In particular, our solution can choose the best configuration for the current video chunk according to the spatial and temporal correlation of video contexts. We implement and evaluate this approach in the object detection task, comparing its performance to static configuration. We show that AutoConfigure achieves 10-35\% higher accuracy with a similar amount of resources or achieves similar accuracy with only 50-85\% of the resources. Our solution proves to be more efficient than static solutions and only creates an overhead of 0.1-1\% to the overall video analytics services.
%and dynamic configuration baseline
\end{abstract}
