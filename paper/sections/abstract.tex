\begin{abstract}
Deep convolutional neural networks (NN)-based video analytics services demands intensive computation resources and high inference accuracy. Due to the highly variable video context, the \emph{best} configuration (the most fitting configuration) for a video analytics services also varies over time. Searching a large space of configurations periodically causes an overwhelming resource overhead that far outstrips the gains of periodically profiling. Knowing this, designing an \emph{automatic} approach to decide what is the best configuration for the current video context is meaningful. In this paper, we propose a reinforcement learning (RL)-based automatic video analytics configuration framework, AutoConfigure. The unique feature of AutoConfigure is \emph{context-driven}, meaning that AutoConfigure can adapt the best configuration to intrusive dynamics of video contexts. In particular, our solution can choose the best configuration for current video chunk according to the spatial and temporal correlation of video contexts. We implement and evaluate this approach in object detection task comparing its performance to static configuration. We show that AutoConfigure achieves 20-30\% higher accuracy with the same amount of resources, or achieve the same accuracy with only 50-70\% of the resources. Furthermore, AutoConfigure proves to be more efficient than existing baselines by creating an overhead of less than xx\%\textcolor{note}{(To be tested)} to the overall video analytics services.
%and dynamic configuration baseline
\end{abstract}
